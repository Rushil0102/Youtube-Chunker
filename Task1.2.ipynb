{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4183afaf-f414-4584-97c0-27a2591d7531",
   "metadata": {},
   "source": [
    "<h1 style=\"color: red;\">Running of script:</h1>\n",
    "<h3 style=\"color: orange;\">Ensure ffmpeg is installed and available in your environment.</h1>\n",
    "<h3 style=\"color: orange;\">The script will prompt the user to enter a YouTube URL and select the video's source language for better translation to English.</h1>\n",
    "<h3 style=\"color: orange;\">The video will be downloaded using the video ID for a unique filename, audio will be extracted to a file with the same unique ID, transcribed to English, and semantic chunks of the transcription will be returned.</h1>\n",
    "<h3 style=\"color: orange;\">Logs will be stored in a file named process_log_<timestamp>.log for each run.</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567e7d2-73e9-4435-a0c7-d39e4c312d71",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\">Step 0: Installalation of libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc282a-ed6c-4fa2-aa5f-5deb930d9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure necessary packages are installed\n",
    "!pip install yt-dlp moviepy openai-whisper gradio pydub\n",
    "\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import time\n",
    "from yt_dlp import YoutubeDL\n",
    "from moviepy.editor import VideoFileClip\n",
    "import whisper\n",
    "import gradio as gr\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# Mapping from language names to language codes\n",
    "LANGUAGE_CODES = {\n",
    "    \"English\": \"en\",\n",
    "    \"Spanish\": \"es\",\n",
    "    \"German\": \"de\",\n",
    "    \"French\": \"fr\",\n",
    "    \"Chinese\": \"zh\",\n",
    "    \"Japanese\": \"ja\",\n",
    "    \"Korean\": \"ko\",\n",
    "    \"Hindi\": \"hi\",\n",
    "    \"Tamil\": \"ta\",\n",
    "    \"Malayalam\": \"ml\",\n",
    "    \"Urdu\": \"ur\",\n",
    "    \"Bengali\": \"bn\",\n",
    "    \"Kannada\": \"kn\",\n",
    "    \"Marathi\": \"mr\",\n",
    "    \"Punjabi\": \"pa\",\n",
    "    # Add more languages as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8017f31-2330-48f1-9170-766daf4f9014",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\">Creation of Log file</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bcf8fb-c105-4e72-ac33-df75222054a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a log file with a unique name based on the current timestamp\n",
    "log_filename = f\"process_log_{int(time.time())}.log\"\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05951e2-4a30-45ce-a4b0-b3051f6fc9ba",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\">Step 1: Download Video and Extract Audio</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed911d-84be-4ce0-b869-97fe72dad981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_id(url):\n",
    "    try:\n",
    "        # Extract the video ID from the URL\n",
    "        match = re.search(r'v=([^&]+)', url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid YouTube URL\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting video ID: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 1: Download Video and Extract Audio\n",
    "\n",
    "def download_youtube_video(url):\n",
    "    try:\n",
    "        video_id = get_video_id(url)\n",
    "        output_path = f\"{video_id}.mp4\"\n",
    "        ydl_opts = {\n",
    "            'format': 'bestvideo+bestaudio/best',\n",
    "            'outtmpl': output_path,\n",
    "            'merge_output_format': 'mp4'\n",
    "        }\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        logging.info(f\"Video downloaded successfully: {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error downloading video: {e}\")\n",
    "        raise RuntimeError(f\"Error downloading video: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90abc65-5b93-4221-a9cd-003ea9001e50",
   "metadata": {},
   "source": [
    "<h4 style=\"color: orange;\">Library: yt-dlp</h1>\n",
    "<h4 style=\"color: orange;\">Reason: yt-dlp is a powerful command-line program to download videos from YouTube and other video platforms. It is a fork of the popular youtube-dl with additional features and bug fixes.</h1>\n",
    "<h4 style=\"color: orange;\">Description: This function takes a YouTube URL, downloads the best available video and audio streams, and merges them into an MP4 file. The yt-dlp library is highly reliable and supports a wide range of video qualities and formats.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4797c60-6ad1-47b3-8f09-41ef84b80da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_from_video(video_path):\n",
    "    try:\n",
    "        audio_path = video_path.replace(\".mp4\", \".wav\")\n",
    "        video = VideoFileClip(video_path)\n",
    "        video.audio.write_audiofile(audio_path)\n",
    "        logging.info(f\"Audio extracted successfully: {audio_path}\")\n",
    "        return audio_path\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting audio: {e}\")\n",
    "        raise RuntimeError(f\"Error extracting audio: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb76a2d7-deeb-4d8b-92ce-c82e5fe43acf",
   "metadata": {},
   "source": [
    "<h4 style=\"color: orange;\">Library: moviepy</h1>\n",
    "<h4 style=\"color: orange;\">Reason: moviepy is a versatile library for video editing in Python. It allows easy manipulation of video and audio files.</h1>\n",
    "<h4 style=\"color: orange;\">Description: This function extracts the audio from the downloaded video and saves it as a WAV file.</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51a90a-dd0f-49c1-b334-282fdb26d25e",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\">Step 2: Transcription of Audio</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ea280-a840-4b81-948c-2df29eb55e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Transcription of Audio\n",
    "\n",
    "def transcribe_audio(audio_path, source_language=None):\n",
    "    try:\n",
    "        # Check if audio file exists\n",
    "        if not os.path.isfile(audio_path):\n",
    "            raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
    "        \n",
    "        # Load the whisper model\n",
    "        model = whisper.load_model(\"base\")\n",
    "        \n",
    "        # Convert language name to code\n",
    "        source_language_code = LANGUAGE_CODES.get(source_language)\n",
    "        \n",
    "        # Set options for transcription, including the source language and target language as English\n",
    "        options = {\"language\": source_language_code} if source_language_code else {}\n",
    "        options[\"task\"] = \"translate\"\n",
    "        \n",
    "        # Transcribe the audio with specified options\n",
    "        result = model.transcribe(audio_path, **options)\n",
    "        \n",
    "        return result[\"text\"], result[\"segments\"]\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error transcribing audio: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa541464-234d-4eed-b2ff-955fd1d7a674",
   "metadata": {},
   "source": [
    "<h4 style=\"color: orange;\">Library: whisper</h1>\n",
    "<h4 style=\"color: orange;\">Reason: whisper is an open-source ASR (Automatic Speech Recognition) model developed by OpenAI. It supports multiple languages and provides high-quality transcription.</h1>\n",
    "<h4 style=\"color: orange;\">Description: This function transcribes the audio file, optionally specifying the language to improve accuracy. It returns the full transcript and individual segments with timestamps.</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66645d51-b151-4528-a049-f0169b6f7a68",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\">Step 3: Semantic Chunking of Data</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e6f9c-273e-460e-b480-827b84eef67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Semantic Chunking of Data\n",
    "\n",
    "def create_semantic_chunks(transcript, segments, max_chunk_length=15.0):\n",
    "    try:\n",
    "        chunks = []\n",
    "        current_chunk = {\"text\": \"\", \"start_time\": None, \"end_time\": None}\n",
    "        for segment in segments:\n",
    "            start_time = segment[\"start\"]\n",
    "            end_time = segment[\"end\"]\n",
    "            text = segment[\"text\"]\n",
    "            if current_chunk[\"start_time\"] is None:\n",
    "                current_chunk[\"start_time\"] = start_time\n",
    "            if (end_time - current_chunk[\"start_time\"]) > max_chunk_length:\n",
    "                current_chunk[\"end_time\"] = end_time\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = {\"text\": \"\", \"start_time\": start_time, \"end_time\": None}\n",
    "            current_chunk[\"text\"] += text + \" \"\n",
    "            current_chunk[\"end_time\"] = end_time\n",
    "        if current_chunk[\"text\"]:\n",
    "            chunks.append(current_chunk)\n",
    "        \n",
    "        logging.info(\"Semantic chunking completed successfully\")\n",
    "        return [{\"chunk_id\": idx + 1, \"chunk_length\": chunk[\"end_time\"] - chunk[\"start_time\"], \"text\": chunk[\"text\"].strip(), \"start_time\": chunk[\"start_time\"], \"end_time\": chunk[\"end_time\"]} for idx, chunk in enumerate(chunks)]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error creating semantic chunks: {e}\")\n",
    "        raise RuntimeError(f\"Error creating semantic chunks: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793239ab-a9d1-4fae-944a-4fd8a12b20b9",
   "metadata": {},
   "source": [
    "<h4 style=\"color: orange;\">Description: This function creates semantic chunks from the transcription segments.</h1>\n",
    "<h4 style=\"color: orange;\">Logic:</h4>\n",
    "<h4 style=\"color: white;\">Initialize: Start with an empty chunk.</h4>\n",
    "<h4 style=\"color: white;\">Iterate Segments: Loop through each segment, accumulating text until the chunk reaches the maximum length.</h4>\n",
    "<h4 style=\"color: white;\">Chunk Creation: If adding a segment would exceed the max chunk length, finalize the current chunk and start a new one.</h4>\n",
    "<h4 style=\"color: white;\">Finalize: Ensure the last chunk is added to the list.</h4>\n",
    "<h4 style=\"color: orange;\">Reasoning: This approach ensures that each chunk is semantically meaningful by grouping segments together and respects the maximum length constraint for manageability.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee2db7-688d-4239-b5a5-577b8893678d",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue;\">Step 4: Gradio Interface for User Interaction</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd990ab-55dd-43a4-ac82-879262700867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio Interface\n",
    "\n",
    "def process_video(url, source_language):\n",
    "    try:\n",
    "        video_path = download_youtube_video(url)\n",
    "        audio_path = extract_audio_from_video(video_path)\n",
    "        \n",
    "        # Get absolute path of the audio file\n",
    "        audio_path = os.path.abspath(audio_path)\n",
    "        \n",
    "        transcript, segments = transcribe_audio(audio_path, source_language)\n",
    "        semantic_chunks = create_semantic_chunks(transcript, segments)\n",
    "        return semantic_chunks\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing video: {e}\")\n",
    "        return str(e)\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=process_video,\n",
    "    inputs=[\n",
    "        gr.inputs.Textbox(lines=2, placeholder=\"Enter YouTube URL here...\"),\n",
    "        gr.inputs.Dropdown(list(LANGUAGE_CODES.keys()), label=\"Select Source Language (for translation to English)\")\n",
    "    ],\n",
    "    outputs=\"json\",\n",
    "    title=\"YouTube Video Semantic Chunker\",\n",
    "    description=\"Extracts high-quality, meaningful (semantic) segments from a YouTube video and translates them to English. Select the source language for better translation accuracy.\"\n",
    ")\n",
    "\n",
    "# Launch Gradio app\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab81d2-f408-47e8-b4b5-19fc49bb608b",
   "metadata": {},
   "source": [
    "<h4 style=\"color: orange;\">Library: gradio</h4>\n",
    "<h4 style=\"color: orange;\">Reason: gradio is a library for creating interactive user interfaces for machine learning models in Python. It allows for easy deployment and user interaction.</h4>\n",
    "<h4 style=\"color: orange;\">Description: This interface allows users to input a YouTube URL and an optional language code, processes the video, and returns the semantic chunks in JSON format.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e265dbba-280f-4bd8-956f-906eb343c18d",
   "metadata": {},
   "source": [
    "<h2 style=\"color: red;\">Strengths and Weaknesses of the Approach</h2>\n",
    "<h3 style=\"color: yellow;\">Strengths:</h3>\n",
    "\n",
    "\n",
    "<h4 style=\"color: white;\">High Precision: By focusing on semantic chunks and limiting the chunk length, the approach ensures high-quality, meaningful segments.</h4>\n",
    "<h4 style=\"color: white;\">Multilingual Support: The use of the Whisper model allows for transcription in multiple languages.</h4>\n",
    "<h4 style=\"color: white;\">User-Friendly Interface: The Gradio app provides an easy-to-use interface for non-technical users.</h4>\n",
    "<h4 style=\"color: white;\">Modular Design: Each step is modular, making it easy to adapt and extend the workflow for different use cases.</h4>\n",
    "\n",
    "<h3 style=\"color: yellow;\">Weaknesses:</h3>\n",
    "<h4 style=\"color: white;\">Dependency on Whisper Model: The approach relies on the Whisper model's language support and accuracy. Unsupported languages or poor model performance on certain accents can affect results.</h4>\n",
    "<h4 style=\"color: white;\">Fixed Chunk Length: The max chunk length is fixed, which might not be optimal for all types of content. More dynamic chunking strategies could be explored.</h4>\n",
    "<h4 style=\"color: white;\">Audio Quality: Poor audio quality or significant background noise can impact transcription accuracy.</h4>\n",
    "<h4 style=\"color: white;\">Computationally Intensive: Processing long videos or videos with high-resolution audio can be computationally intensive and time-consuming.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da0548c-4196-4332-91b7-8b40d86cca19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
